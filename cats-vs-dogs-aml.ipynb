{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# The problem: Cats vs Dogs\n\nIn this problem, we have to write an algorithm to classify whether images contain either a dog or a cat. This is easy for humans, dogs, and cats, but your computer will find it a bit more difficult.\n\n<img src='https://storage.googleapis.com/kaggle-competitions/kaggle/3362/media/woof_meow.jpg' />\n\n#### The Asirra data set\nWeb services are often protected with a challenge that's supposed to be easy for people to solve, but difficult for computers. Such a challenge is often called a CAPTCHA (Completely Automated Public Turing test to tell Computers and Humans Apart) or HIP (Human Interactive Proof). HIPs are used for many purposes, such as to reduce email and blog spam and prevent brute-force attacks on web site passwords.\n\nAsirra (Animal Species Image Recognition for Restricting Access) is a HIP that works by asking users to identify photographs of cats and dogs. This task is difficult for computers, but studies have shown that people can accomplish it quickly and accurately. Many even think it's fun! Here is an example of the Asirra interface:\n\nAsirra is unique because of its partnership with Petfinder.com, the world's largest site devoted to finding homes for homeless pets. They've provided Microsoft Research with over three million images of cats and dogs, manually classified by people at thousands of animal shelters across the United States. Kaggle is fortunate to offer a subset of this data for fun and research. \n        "
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Solving the problem\n\nLet's start by getting some undestanding of the problem. This is what we know:\n\n<ul>\n    <li><b>Problem type:</b> Classification</li>\n    <li><b>Number of classes:</b> 2 (cats, dogs)</li>\n    <li><b>Input:</b> Images (25.000 — 50% cats, 50% dogs)</li>\n</ul>\n\nThe dataset is completely balanced, and "
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Azure Machine Learning Services\n\nMicrosoft has a variety of services tailored for Machine Learning and AI, however, the most suitable for this talk is by far AML. It provides a cloud-based environment you can use to develop, train, test, deploy, manage, and track machine learning models. The current version of AML uses a code-first approach with Python, which means that the whole process is managed using this language. It can be executed from a notebook or from the IDE of your choice."
    },
    {
      "metadata": {
        "collapsed": true
      },
      "cell_type": "markdown",
      "source": "## Install the SDK\n\nAs I stated before, AML uses a code-first approach to create, manage and publish machine learning experiments. So you will need to install some libraries in your environment. Your environment could be your local computer using PyCharm, Spider, VS Code or any other IDE of your choice, or it can be a notebook running in the cloud or locally. You need to install two libraries: Azure and Azure ML SDK."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "!pip install azureml-sdk[notebooks,automl] --ignore-installed",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<h2>A Machine Learning workspace</h2>\n\nFirst, we are going to create a workspace in AML to work with. The workspace is the cloud resource you will use to create, manage, and publish machine learning experiments. To create a workspace you need the subscription ID of the subscription you are going to use, a name for the workspace and a location to deploy the resource. The location parameter is important since it will define which compute hardware will be available for your training job. I’m using East of US."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import azureml.core\nfrom azureml.core.workspace import Workspace\nws = Workspace.get(\n     name = \"aa-ml-aml-workspace\",\n     subscription_id = \"\",\n     resource_group = 'Analytics.Aml.Experiments.Workspaces')",
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<h2>Experiment</h2>\n\nAn experiment is a logical container for your proposed solution to the problem you want to model. A workspace can have multiple experiments running at the same time. They don’t just work as a container for your solution, but they also allow you to track down your progress around how good your solution is doing. Such progress is tracked using metrics you can define. If your problem is a classification problem, probably you will want to track the Accuracy or the MAP your model is getting. Each experiment can have multiple metrics being tracked.\n\nYour experiment will be associated with a folder on your local computer. Such a folder contains all the resources (code files, assets, data, etc) you need to solve the problem. The folder will typically be associated with a code repository. This is not required, but it will allow you to collaborate among different Data Scientists in the same experiment. The repository can be hosted in any service, from GitHub to Azure DevOps.\n\nYou create an experiment using Python by simply indicating the name of the experiment and the Workspace associated with it."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.core import Experiment\nexperiment = Experiment(workspace=ws, name='azureml-cats-vs-dogs')",
      "execution_count": 10,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<b>State of the art</b>\n\nThe current literature suggests machine classifiers can score above 80% accuracy on this task. Therfore, Asirra is no longer considered safe from attack. Current Top 1 Kaggle leader achieved 0.98914. Let's try to implement a solution using Machine Learning. "
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Creating a train script: Solving the problem with fast.ai and PyTorch\n\nWe are introducing here a framework called fast.ai (https://www.fast.ai/), a framework based on PyTorch with some handy operations already implemented to speed up problem solving quickly. To use fast.ai, we need to import 2 libraries: fastai and torch. fast.ai also has the named dataset already uploaded as part of the framework, which makes pretty convenient to work with it. The following line unzipes the compressed tar file where all the dataset is stored.\n\n```python\npath = untar_data(URLs.DOGS)\n```\n\nAs images are unzipped in a folder, we need to create a dataset to use for training and testing. fast.ai has a very simple way to do that. The method ImageDataBunch.from_folder creates a dataset of images using as parameters path (where the files are stored inside 2 folders, cats and dogs each of them representing one class), ds_tfms indicating which image transformations to apply and size specifying the size of the images used. The way folders are read is as images in the same subfolder are considered one class. The ds_tfms() method quickly gets a set of random transforms that have proved to work well in a wide range of tasks in computer vision, including a random flip is applied with probability 0.5, a random rotation, a random zoom, a random lightning and contrast change and a random symmetric warp. Images will be altered somehow similar to the following:\n\n```python\ndata = ImageDataBunch.from_folder(path, ds_tfms=get_transforms(), size=224)\n```\n\n<img src='https://notebooks.azure.com/fasantia/projects/hol-aml-experimentationservice/raw/docs%2Fimg_cats_transform.png' />\n\nFinally, the function normalize creates a normalize/denormalize func using an specific mean and std. In this case, those parameters are taken from the imagenet dataset, using the values imagenet_stats which are means = [0.485, 0.456, 0.406] and stds = [0.229, 0.224, 0.225].\n\n```python\ndata = ImageDataBunch.from_folder(path, ds_tfms=get_transforms(), size=224).normalize(imagenet_stats)\n```"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Once our dataset is ready, it's time to create our NN. CNN represents a very convenient way to solve Computer Vision problems, specially when combined with transfer learning. We use transfer learning with a pretrained image classification models to extract visual features. The idea behind it is that the representations learned for task A (typically a high-level task) are applied to task B (typically a lower-level task) as for the degree of success at task B indicates how much the task A model has learned about task B.\n\n```python\nlearn = create_cnn(data, models.resnet50, metrics=accuracy)\n```"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Then it's time to train. When using transfer learning, the training process is a bit different like in a normal network. In the processes we take a pre-trained model and “fine-tuning” the model with your our own dataset. The idea is that this pre-trained model will act as a feature extractor. You will remove the last layer of the network and replace it with your own classifier. You then freeze the weights of all the other layers and train the network normally. This is exactly what the following 3 lines are doing:\n\n```python\nlearn.fit_one_cycle(1)\nlearn.unfreeze()\nlearn.fit_one_cycle(1, slice(1e-5,3e-4), pct_start=0.05)\n```"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "I'm using here the method fit_one_cycle for training the model. What this method does behind the scenes is running for few epochs to find out a good learning rate, where it trains from some low learning rate and increase the learning rate after each mini-batch till the loss value starts to explode. This single run provides valuable information on how well the network can be trained over a range of learning rates and what is the maximum learning rate. This is based on a paper https://arxiv.org/abs/1506.01186 which is a really good reading by the way. In Cyclical learning rates (CLR) one specifies minimum and maximum learning rate boundaries and a stepsize. The stepsize is the number of iterations (or epochs) used for each step and a cycle consists of two such steps – one in which the learning rate linearly increases from the minimum to the maximum and the other in which it linearly decreases."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Once the model is trained, it's time to save the work. The save method will save the model and all the required files used when training. The export method will also create a pkl file which can be used later to make predictions based on new images.\n\n```python\nsaved_model_path = learn.save(name='cats-vs-dogs', return_path = True)\nlearn.export()\n```"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Let's put all the peaces together now into a single train file"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "%%writefile fastai/train.py\n\nimport torch\nimport numpy as np\nimport fastai\nfrom fastai import *\nfrom fastai.vision import *\n\npath = untar_data(URLs.DOGS)\ndata = ImageDataBunch.from_folder(path, ds_tfms=get_transforms(), size=224).normalize(imagenet_stats)\nlearn = create_cnn(data, models.resnet50, metrics=accuracy)\n\nlearn.fit_one_cycle(1)\nlearn.unfreeze()\nlearn.fit_one_cycle(1, slice(1e-5,3e-4), pct_start=0.05)\n\nsaved_model_path = learn.save(name='cats-vs-dogs', return_path = True)\nlearn.export()",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Overwriting fastai/train.py\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Creating a better version of train.py"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Althought the previous train.py file would do the job, it would be great if we can take advantage of some of the features Azure Machine Learning offers, specially regarding metric's tracking. We can achieve that by using the get_context() method to get the current execution context inside Azure Machine Learning Services:\n\n```python\nfrom azureml.core import Run\nrun = Run.get_context()\n```\n\nThen, we can log specific metrics using the log method:\n\n```python\nrun.log('training_acc', accuracy_value)\n```\n\nI'm also using the method run.log_list to log a sequence of values, which will be later displayed as a graph in the Azure Dashboard. In particular, I'm logging the learning rate and the loss which I will use to know if the model is overfitting the training data set or not. You will see that I use a method called reduce_list. This is used to reduce the number of points to plot. Currently, the method has a limit of points you can submit.\n\nThe new version of the train.py file will look like this:"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### The train.py script (v2)"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "%%writefile fastai/train.py\n\nimport torch\nimport numpy as np\nimport fastai\nfrom fastai import *\nfrom fastai.vision import *\n\nprint(\"PyTorch version %s\" % torch.__version__)\nprint(\"fastai version: %s\" % fastai.__version__)\nprint(\"CUDA supported: %s\" % torch.cuda.is_available())\nprint(\"CUDNN enabled: %s\" % torch.backends.cudnn.enabled)\n\npath = untar_data(URLs.DOGS)\ndata = ImageDataBunch.from_folder(path, ds_tfms=get_transforms(), size=224).normalize(imagenet_stats)\nlearn = create_cnn(data, models.resnet50, metrics=accuracy)\n\nlearn.fit_one_cycle(1)\nlearn.unfreeze()\nlearn.fit_one_cycle(1, slice(1e-5,3e-4), pct_start=0.05)\n\nsaved_model_path = learn.save(name='cats-vs-dogs', return_path = True)\nlearn.export()\nsaved_model_pkl = str(learn.path) + '/export.pkl'\n\nfrom azureml.core import Run\nrun = Run.get_context()\n\ndef reduce_list(all_values):\n    return [np.max(all_values[i:i+10]) for i in range(0,len(all_values)-1,10)]\n\nlosses_values = [tensor.item() for tensor in learn.recorder.losses] \naccuracy_value = np.float(accuracy(*learn.TTA()))\n\nrun.log('training_acc', accuracy_value)\nrun.log('pytorch', torch.__version__)\nrun.log('fastai', fastai.__version__)\nrun.log('base_model', 'resnet50')\nrun.log_list('Learning_rate', reduce_list(learn.recorder.lrs))\nrun.log_list('Loss', reduce_list(losses_values))\n\nfrom shutil import copyfile\ncopyfile(saved_model_pkl, './outputs/cats-vs-dogs.pkl')",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Overwriting fastai/train.py\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "In the last 2 lines I'm saving the model in the folder outputs. The reason for that is that AMLS automatically capture all the files in that directory and saves it in the workspace. Then you can download the trained model to use later."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<h1>What, where and how to execute the training</h1>\n<h2>Run configuration and Estimators</h2>\n\nThe Estimator is an abstraction that allows you especify how the train.py file should be executed based on high-level specifications. You create an Estimator using the azureml.train.Estimator namespace, however, the SDK cames with some Estimators prebuilt for specific deep learning frameworks, including TensorFlow and PyTorch. If you are using one of those frameworks, then you can create an Estimator for them as follows:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.train.dnn import PyTorch\nsrc = PyTorch(source_directory =  r'fastai',\n              entry_script = 'train.py',\n              compute_target='amlcompute', \n              vm_size='Standard_NC6', \n              use_gpu = True, \n              pip_packages = ['fastai==1.0.0', 'azureml-sdk'])",
      "execution_count": 13,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "This method will create a PyTorch execution environment. Parameters are:\n\n<ul>\n    <li><b>souce_directory:</b> All the files in souce_directory will be copies to the execution target (this is usually your project root directory).</li>\n    <li><b>compute_target</b> specified where are you going to execute this job. The value ‘amlcompute’ signals we want Azure to provision a VM for this specific job. The machine will be created and once the job is done it will be destroyed. Pretty cool feature. Other types are available including (Databricks, HDInsight (Spark), custom VMs, local computer)</li>\n    <li><b>vm_size</b> specified the type of hardware to use. In this case, Standard_NC6 are powered by NVIDIA Tesla K80 with 8 GiB, 6 vCPU, and 56 GiB of RAM.</li>\n    <li><b>entry_script</b> specified which is the training script you want to execute. This file should be inside of source_directory.</li>\n    <li><b>use_gpu</b> specifies that we want GPU-enabled libraries.</li>\n    <li><b>pip_packages</b> allows you to specify which additional packages you need in the execution environment. In this case, since PyTorch execution environment has everything that is needed for PyTorch, the only package that is missing is fast.ai.</li>\n</ul>"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<h2>Runs</h2>\n\nInside an experiment, you have Runs. A Run is a particular instance of the experiment. Each time you submit your experiment to Azure and execute it, it will create a Run. You will typically collect metrics across different runs, for instance, the accuracy the model is getting, in order to compare. This is how you can track progress in your model manage how it evolves. The run can also generate outputs. Typically, one of the outputs will be the model itself (a file).\n\nYou create a run for your experiment by executing the submit method of the experiment object."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "run = experiment.submit(src)",
      "execution_count": 14,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Once a run is submitted, the training process for your experiment will start. The method is asynchronous, that means that it will not wait until it is done. You will typically want to wait for it. wait_for_completion does that for you. The show_output = true indicated that you want to see the output of the process in your console. The output will be a live stream so you can see exactly what’s going on. Kind of cool!\n\nWhat is happening under the hood is that Azure is preparing a new docker image for executing PyTorch code with GPU support, copying all the assets we need, installing all the packages we specified, creating a VM and deploying the image in the VM. Finally, the script is executed and once done the VM destroyed."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "run.wait_for_completion(show_output = True)",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": "RunId: azureml-cats-vs-dogs_1554821600_f6d06459\n\nStreaming azureml-logs/20_image_build_log.txt\n=============================================\n\n2019/04/09 14:54:18 Using acb_vol_9cd7a6d1-b8ab-49bf-91f9-7f5a366c8cad as the home volume\n2019/04/09 14:54:18 Creating Docker network: acb_default_network, driver: 'bridge'\n2019/04/09 14:54:18 Successfully set up Docker network: acb_default_network\n2019/04/09 14:54:18 Setting up Docker configuration...\n2019/04/09 14:54:19 Successfully set up Docker configuration\n2019/04/09 14:54:19 Logging in to registry: aamlamlwacrhtyjtxxl.azurecr.io\n2019/04/09 14:54:20 Successfully logged into aamlamlwacrhtyjtxxl.azurecr.io\n2019/04/09 14:54:20 Executing step ID: acb_step_0. Working directory: '', Network: 'acb_default_network'\n2019/04/09 14:54:20 Obtaining source code and scanning for dependencies...\n2019/04/09 14:54:21 Successfully obtained source code and scanned for dependencies\n2019/04/09 14:54:21 Launching container with name: acb_step_0\nSending build context to Docker daemon  45.06kB\n\nStep 1/15 : FROM mcr.microsoft.com/azureml/base-gpu:0.2.1@sha256:eb26cf5e4a6852a3b9029299ee17424b31f458b293066c11824135530617a073\nsha256:eb26cf5e4a6852a3b9029299ee17424b31f458b293066c11824135530617a073: Pulling from azureml/base-gpu\n7b722c1070cd: Already exists\n5fbf74db61f1: Already exists\ned41cb72e5c9: Already exists\n7ea47a67709e: Already exists\ne986a5da9812: Pulling fs layer\nfcf92330fc84: Pulling fs layer\n93f701a1b3a0: Pulling fs layer\n52ab5449a7fb: Pulling fs layer\nad2cbdb1079e: Pulling fs layer\ndf677fc43fdf: Pulling fs layer\n220ea4374d17: Pulling fs layer\n52ab5449a7fb: Waiting\nad2cbdb1079e: Waiting\ndf677fc43fdf: Waiting\n220ea4374d17: Waiting\ne986a5da9812: Verifying Checksum\ne986a5da9812: Download complete\ne986a5da9812: Pull complete\nfcf92330fc84: Verifying Checksum\nfcf92330fc84: Download complete\n93f701a1b3a0: Verifying Checksum\n93f701a1b3a0: Download complete\nad2cbdb1079e: Verifying Checksum\nad2cbdb1079e: Download complete\n52ab5449a7fb: Verifying Checksum\n52ab5449a7fb: Download complete\ndf677fc43fdf: Verifying Checksum\ndf677fc43fdf: Download complete\nfcf92330fc84: Pull complete\n93f701a1b3a0: Pull complete\n52ab5449a7fb: Pull complete\nad2cbdb1079e: Pull complete\ndf677fc43fdf: Pull complete\n220ea4374d17: Verifying Checksum\n220ea4374d17: Download complete\n220ea4374d17: Pull complete\nDigest: sha256:eb26cf5e4a6852a3b9029299ee17424b31f458b293066c11824135530617a073\nStatus: Downloaded newer image for mcr.microsoft.com/azureml/base-gpu:0.2.1@sha256:eb26cf5e4a6852a3b9029299ee17424b31f458b293066c11824135530617a073\n ---> b1d15c3ed71e\nStep 2/15 : USER root\n ---> Running in 0675afac8feb\nRemoving intermediate container 0675afac8feb\n ---> 78533c9b9420\nStep 3/15 : RUN mkdir -p $HOME/.cache\n ---> Running in 8af14d54bb21\nRemoving intermediate container 8af14d54bb21\n ---> 23c3cbb5c84e\nStep 4/15 : WORKDIR /\n ---> Running in 6ec10a457345\nRemoving intermediate container 6ec10a457345\n ---> 0617799a84ec\nStep 5/15 : COPY azureml-setup/99brokenproxy /etc/apt/apt.conf.d/\n ---> 7a680200a397\nStep 6/15 : RUN if dpkg --compare-versions `conda --version | grep -oE '[^ ]+$'` lt 4.4.11; then conda install conda==4.4.11; fi\n ---> Running in 7b935b596065\nRemoving intermediate container 7b935b596065\n ---> 5bc289d91d22\nStep 7/15 : COPY azureml-setup/mutated_conda_dependencies.yml azureml-setup/mutated_conda_dependencies.yml\n ---> 8debfa1d2c9d\nStep 8/15 : RUN ldconfig /usr/local/cuda/lib64/stubs && conda env create -p /azureml-envs/azureml_e7a13acf77779904bb28653701c4bd3a -f azureml-setup/mutated_conda_dependencies.yml && conda clean -aqy && CONDA_ROOT_DIR=$(conda info --root) && rm -rf \"$CONDA_ROOT_DIR/pkgs\" && find \"$CONDA_ROOT_DIR\" -type d -name __pycache__ -exec rm -rf {} + && ldconfig\n ---> Running in 06ed5edfb4a1\nSolving environment: ...working... done\n\u001b[91m\n\n==> WARNING: A newer version of conda exists. <==\n  current version: 4.5.11\n  latest version: 4.6.11\n\nPlease update conda by running\n\n    $ conda update -n base -c defaults conda\n\n\n\npip-19.0.3           | 1.9 MB    |            |   0% \u001b[0m\u001b[91m\npip-19.0.3           | 1.9 MB    | #######9   |  79% \u001b[0m\u001b[91m\npip-19.0.3           | 1.9 MB    | #########8 |  99% \u001b[0m\u001b[91m\npip-19.0.3           | 1.9 MB    | ########## | 100% \u001b[0m\u001b[91m\n\nca-certificates-2019 | 126 KB    |            |   0% \u001b[0m\u001b[91m\nca-certificates-2019 | 126 KB    | ########## | 100% \u001b[0m\u001b[91m\n\nlibgcc-ng-8.2.0      | 7.6 MB    |            |   0% \u001b[0m\u001b[91m\nlibgcc-ng-8.2.0      | 7.6 MB    | #######5   |  76% \u001b[0m\u001b[91m\nlibgcc-ng-8.2.0      | 7.6 MB    | #########4 |  94% \u001b[0m\u001b[91m\nlibgcc-ng-8.2.0      | 7.6 MB    | ########## | 100% \u001b[0m\u001b[91m\n\nzlib-1.2.11          | 120 KB    |            |   0% \u001b[0m\u001b[91m\nzlib-1.2.11          | 120 KB    | ########## | 100% \u001b[0m\u001b[91m\n\nreadline-7.0         | 1.1 MB    |            |   0% \u001b[0m\u001b[91m\nreadline-7.0         | 1.1 MB    | ########6  |  87% \u001b[0m\u001b[91m\nreadline-7.0         | 1.1 MB    | ########## | 100% \u001b[0m\u001b[91m\n\ntk-8.6.8             | 3.1 MB    |            |   0% \u001b[0m\u001b[91m\ntk-8.6.8             | 3.1 MB    | #######6   |  77% \u001b[0m\u001b[91m\ntk-8.6.8             | 3.1 MB    | #########1 |  91% \u001b[0m\u001b[91m\ntk-8.6.8             | 3.1 MB    | ########## | 100% \u001b[0m\u001b[91m\n\nopenssl-1.0.2r       | 3.2 MB    |            |   0% \u001b[0m\u001b[91m\nopenssl-1.0.2r       | 3.2 MB    | #######6   |  77% \u001b[0m\u001b[91m\nopenssl-1.0.2r       | 3.2 MB    | #########9 | 100% \u001b[0m\u001b[91m\nopenssl-1.0.2r       | 3.2 MB    | ########## | 100% \u001b[0m\u001b[91m\n\nncurses-6.0          | 920 KB    |            |   0% \u001b[0m\u001b[91m\nncurses-6.0          | 920 KB    | #######9   |  79% \u001b[0m\u001b[91m\nncurses-6.0          | 920 KB    | #########2 |  93% \u001b[0m\u001b[91m\nncurses-6.0          | 920 KB    | ########## | 100% \u001b[0m\u001b[91m\n\nlibedit-3.1          | 171 KB    |            |   0% \u001b[0m\u001b[91m\nlibedit-3.1          | 171 KB    | ########## | 100% \u001b[0m\u001b[91m\n\nlibffi-3.2.1         | 43 KB     |            |   0% \u001b[0m\u001b[91m\nlibffi-3.2.1         | 43 KB     | ########## | 100% \u001b[0m\u001b[91m\n\nsqlite-3.23.1        | 1.5 MB    |            |   0% \u001b[0m\u001b[91m\nsqlite-3.23.1        | 1.5 MB    | ########4  |  85% \u001b[0m\u001b[91m\nsqlite-3.23.1        | 1.5 MB    | ########## | 100% \u001b[0m\u001b[91m\n\npython-3.6.2         | 27.0 MB   |            |   0% \u001b[0m\u001b[91m\npython-3.6.2         | 27.0 MB   | 4          |   5% \u001b[0m\u001b[91m\npython-3.6.2         | 27.0 MB   | ###5       |  36% \u001b[0m\u001b[91m\npython-3.6.2         | 27.0 MB   | ######7    |  67% \u001b[0m\u001b[91m\npython-3.6.2         | 27.0 MB   | ########3  |  84% \u001b[0m\u001b[91m\npython-3.6.2         | 27.0 MB   | #########5 |  96% \u001b[0m\u001b[91m\npython-3.6.2         | 27.0 MB   | ########## | 100% \u001b[0m\u001b[91m\n\nsetuptools-40.8.0    | 647 KB    |            |   0% \u001b[0m\u001b[91m\nsetuptools-40.8.0    | 647 KB    | #########4 |  94% \u001b[0m\u001b[91m\nsetuptools-40.8.0    | 647 KB    | ########## | 100% \u001b[0m\u001b[91m\n\ncertifi-2019.3.9     | 155 KB    |            |   0% \u001b[0m\u001b[91m\ncertifi-2019.3.9     | 155 KB    | ########## | 100% \u001b[0m\u001b[91m\n\nxz-5.2.4             | 366 KB    |            |   0% \u001b[0m\u001b[91m\nxz-5.2.4             | 366 KB    | ########## | 100% \u001b[0m\u001b[91m\n\nlibstdcxx-ng-8.2.0   | 2.9 MB    |            |   0% \u001b[0m\u001b[91m\nlibstdcxx-ng-8.2.0   | 2.9 MB    | #######7   |  78% \u001b[0m\u001b[91m\nlibstdcxx-ng-8.2.0   | 2.9 MB    | ########## | 100% \u001b[0m\u001b[91m\n\nwheel-0.33.1         | 39 KB     |            |   0% \u001b[0m\u001b[91m\nwheel-0.33.1         | 39 KB     | ########## | 100% \u001b[0m\nDownloading and Extracting Packages\nPreparing transaction: ...working... done\nVerifying transaction: ...working... done\nExecuting transaction: ...working... done\nCollecting azureml-defaults (from -r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 1))\n  Downloading https://files.pythonhosted.org/packages/4b/db/dd3480414f0ff182154d9b78053159815b6ae82a76336b0da5362952826e/azureml_defaults-1.0.23-py2.py3-none-any.whl\nCollecting torch==1.0.0 (from -r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 2))\n  Downloading https://files.pythonhosted.org/packages/7e/60/66415660aa46b23b5e1b72bc762e816736ce8d7260213e22365af51e8f9c/torch-1.0.0-cp36-cp36m-manylinux1_x86_64.whl (591.8MB)\nCollecting torchvision==0.2.1 (from -r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 3))\n  Downloading https://files.pythonhosted.org/packages/ca/0d/f00b2885711e08bd71242ebe7b96561e6f6d01fdb4b9dcf4d37e2e13c5e1/torchvision-0.2.1-py2.py3-none-any.whl (54kB)\nCollecting fastai (from -r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 4))\n  Downloading https://files.pythonhosted.org/packages/44/cc/dcc702cf43bb8c908d172e5be156615928f962366a20834c320cbca2b9d0/fastai-1.0.51-py3-none-any.whl (214kB)\nCollecting azureml-sdk (from -r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 5))\n  Downloading https://files.pythonhosted.org/packages/b4/1e/c212b6f5b7fc4e8dbc80032c9bb0e0b0653dfb7171fb56d94b4442fb6877/azureml_sdk-1.0.23-py3-none-any.whl\nCollecting azureml-core==1.0.23.* (from azureml-defaults->-r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 1))\n  Downloading https://files.pythonhosted.org/packages/c0/44/422e114516ff2b4bafbaa3e53cd19e0bbbe36bf594981e5817610430e3a7/azureml_core-1.0.23-py2.py3-none-any.whl (811kB)\nCollecting applicationinsights>=0.11.7 (from azureml-defaults->-r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 1))\n  Downloading https://files.pythonhosted.org/packages/de/bc/8e738cc3b74551c1a63889ff32c4456c22246ec89cfae3bf6a0a126a29c8/applicationinsights-0.11.8-py2.py3-none-any.whl (58kB)\nCollecting six (from torchvision==0.2.1->-r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 3))\n  Downloading https://files.pythonhosted.org/packages/73/fb/00a976f728d0d1fecfe898238ce23f502a721c0ac0ecfedb80e0d88c64e9/six-1.12.0-py2.py3-none-any.whl\nCollecting pillow>=4.1.1 (from torchvision==0.2.1->-r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 3))\n  Downloading https://files.pythonhosted.org/packages/d2/c2/f84b1e57416755e967236468dcfb0fad7fd911f707185efc4ba8834a1a94/Pillow-6.0.0-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\nCollecting numpy (from torchvision==0.2.1->-r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 3))\n  Downloading https://files.pythonhosted.org/packages/35/d5/4f8410ac303e690144f0a0603c4b8fd3b986feb2749c435f7cdbb288f17e/numpy-1.16.2-cp36-cp36m-manylinux1_x86_64.whl (17.3MB)\nCollecting beautifulsoup4 (from fastai->-r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 4))\n  Downloading https://files.pythonhosted.org/packages/1d/5d/3260694a59df0ec52f8b4883f5d23b130bc237602a1411fa670eae12351e/beautifulsoup4-4.7.1-py3-none-any.whl (94kB)\nCollecting pyyaml (from fastai->-r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 4))\n  Downloading https://files.pythonhosted.org/packages/9f/2c/9417b5c774792634834e730932745bc09a7d36754ca00acf1ccd1ac2594d/PyYAML-5.1.tar.gz (274kB)\nCollecting bottleneck (from fastai->-r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 4))\n  Downloading https://files.pythonhosted.org/packages/05/ae/cedf5323f398ab4e4ff92d6c431a3e1c6a186f9b41ab3e8258dff786a290/Bottleneck-1.2.1.tar.gz (105kB)\nCollecting numexpr (from fastai->-r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 4))\n  Downloading https://files.pythonhosted.org/packages/0e/13/d38d56c4c49e50b35b6912c80d89f856d50aff605c9e3a4dbba91fc3df44/numexpr-2.6.9-cp36-cp36m-manylinux1_x86_64.whl (163kB)\nCollecting nvidia-ml-py3 (from fastai->-r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 4))\n  Downloading https://files.pythonhosted.org/packages/6d/64/cce82bddb80c0b0f5c703bbdafa94bfb69a1c5ad7a79cff00b482468f0d3/nvidia-ml-py3-7.352.0.tar.gz\nCollecting pandas (from fastai->-r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 4))\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "  Downloading https://files.pythonhosted.org/packages/19/74/e50234bc82c553fecdbd566d8650801e3fe2d6d8c8d940638e3d8a7c5522/pandas-0.24.2-cp36-cp36m-manylinux1_x86_64.whl (10.1MB)\nCollecting fastprogress>=0.1.19 (from fastai->-r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 4))\n  Downloading https://files.pythonhosted.org/packages/83/db/794db47024a26c75635c35f0ee5431aa8b528e895ad1ed958041290f83f7/fastprogress-0.1.21-py3-none-any.whl\nCollecting packaging (from fastai->-r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 4))\n  Downloading https://files.pythonhosted.org/packages/91/32/58bc30e646e55eab8b21abf89e353f59c0cc02c417e42929f4a9546e1b1d/packaging-19.0-py2.py3-none-any.whl\nCollecting typing (from fastai->-r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 4))\n  Downloading https://files.pythonhosted.org/packages/4a/bd/eee1157fc2d8514970b345d69cb9975dcd1e42cd7e61146ed841f6e68309/typing-3.6.6-py3-none-any.whl\nCollecting scipy (from fastai->-r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 4))\n  Downloading https://files.pythonhosted.org/packages/7f/5f/c48860704092933bf1c4c1574a8de1ffd16bf4fde8bab190d747598844b2/scipy-1.2.1-cp36-cp36m-manylinux1_x86_64.whl (24.8MB)\nCollecting requests (from fastai->-r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 4))\n  Downloading https://files.pythonhosted.org/packages/7d/e3/20f3d364d6c8e5d2353c72a67778eb189176f08e873c9900e10c0287b84b/requests-2.21.0-py2.py3-none-any.whl (57kB)\nCollecting matplotlib (from fastai->-r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 4))\n  Downloading https://files.pythonhosted.org/packages/e9/69/f5e05f578585ed9935247be3788b374f90701296a70c8871bcd6d21edb00/matplotlib-3.0.3-cp36-cp36m-manylinux1_x86_64.whl (13.0MB)\nCollecting dataclasses; python_version < \"3.7\" (from fastai->-r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 4))\n  Downloading https://files.pythonhosted.org/packages/26/2f/1095cdc2868052dd1e64520f7c0d5c8c550ad297e944e641dbf1ffbb9a5d/dataclasses-0.6-py3-none-any.whl\nCollecting spacy>=2.0.18 (from fastai->-r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 4))\n  Downloading https://files.pythonhosted.org/packages/52/da/3a1c54694c2d2f40df82f38a19ae14c6eb24a5a1a0dae87205ebea7a84d8/spacy-2.1.3-cp36-cp36m-manylinux1_x86_64.whl (27.7MB)\nCollecting azureml-pipeline==1.0.23.* (from azureml-sdk->-r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 5))\n  Downloading https://files.pythonhosted.org/packages/6e/cd/0c486837c08043b5585f786361c984204243271aa053d54e0d23f00972d9/azureml_pipeline-1.0.23-py3-none-any.whl\nCollecting azureml-train==1.0.23.* (from azureml-sdk->-r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 5))\n  Downloading https://files.pythonhosted.org/packages/13/2e/502256481598b900d907a9308e3cf7d75a7d53df368e41456a161fe5f7cd/azureml_train-1.0.23-py3-none-any.whl\nCollecting azure-mgmt-authorization>=0.40.0 (from azureml-core==1.0.23.*->azureml-defaults->-r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 1))\n  Downloading https://files.pythonhosted.org/packages/a1/71/9a20913e92771b3c23564f1bea54d376d09fb30a75585087c70b769d75c8/azure_mgmt_authorization-0.51.1-py2.py3-none-any.whl (111kB)\nCollecting azure-mgmt-resource>=1.2.1 (from azureml-core==1.0.23.*->azureml-defaults->-r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 1))\n  Downloading https://files.pythonhosted.org/packages/2b/2e/e79a278bedfc21308ab0c632759cfda5d7ff02d62260bcc4632449937dcf/azure_mgmt_resource-2.1.0-py2.py3-none-any.whl (757kB)\nCollecting docker (from azureml-core==1.0.23.*->azureml-defaults->-r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 1))\n  Downloading https://files.pythonhosted.org/packages/48/68/c3afca1a5aa8d2997ec3b8ee822a4d752cf85907b321f07ea86888545152/docker-3.7.2-py2.py3-none-any.whl (134kB)\nCollecting jmespath (from azureml-core==1.0.23.*->azureml-defaults->-r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 1))\n  Downloading https://files.pythonhosted.org/packages/83/94/7179c3832a6d45b266ddb2aac329e101367fbdb11f425f13771d27f225bb/jmespath-0.9.4-py2.py3-none-any.whl\nCollecting PyJWT (from azureml-core==1.0.23.*->azureml-defaults->-r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 1))\n  Downloading https://files.pythonhosted.org/packages/87/8b/6a9f14b5f781697e51259d81657e6048fd31a113229cf346880bb7545565/PyJWT-1.7.1-py2.py3-none-any.whl\nCollecting ruamel.yaml<=0.15.89,>=0.15.35 (from azureml-core==1.0.23.*->azureml-defaults->-r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 1))\n  Downloading https://files.pythonhosted.org/packages/36/e1/cc2fa400fa5ffde3efa834ceb15c464075586de05ca3c553753dcd6f1d3b/ruamel.yaml-0.15.89-cp36-cp36m-manylinux1_x86_64.whl (651kB)\nCollecting pathspec (from azureml-core==1.0.23.*->azureml-defaults->-r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 1))\n  Downloading https://files.pythonhosted.org/packages/84/2a/bfee636b1e2f7d6e30dd74f49201ccfa5c3cf322d44929ecc6c137c486c5/pathspec-0.5.9.tar.gz\nCollecting azure-mgmt-keyvault>=0.40.0 (from azureml-core==1.0.23.*->azureml-defaults->-r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 1))\n  Downloading https://files.pythonhosted.org/packages/49/de/0d69aedae7c5f6428314640b65947203ab80409c12b5d4e66fb5b7a4182e/azure_mgmt_keyvault-1.1.0-py2.py3-none-any.whl (111kB)\nCollecting pyopenssl (from azureml-core==1.0.23.*->azureml-defaults->-r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 1))\n  Downloading https://files.pythonhosted.org/packages/01/c8/ceb170d81bd3941cbeb9940fc6cc2ef2ca4288d0ca8929ea4db5905d904d/pyOpenSSL-19.0.0-py2.py3-none-any.whl (53kB)\nCollecting msrestazure>=0.4.33 (from azureml-core==1.0.23.*->azureml-defaults->-r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 1))\n  Downloading https://files.pythonhosted.org/packages/46/ba/7870308e3d3b4b3956880eed2df20669a5690436793e6fc1442c8b73e01c/msrestazure-0.6.0-py2.py3-none-any.whl\nCollecting pytz (from azureml-core==1.0.23.*->azureml-defaults->-r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 1))\n  Downloading https://files.pythonhosted.org/packages/61/28/1d3920e4d1d50b19bc5d24398a7cd85cc7b9a75a490570d5a30c57622d34/pytz-2018.9-py2.py3-none-any.whl (510kB)\nCollecting azure-common>=1.1.12 (from azureml-core==1.0.23.*->azureml-defaults->-r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 1))\n  Downloading https://files.pythonhosted.org/packages/c3/f8/46248b201fd38b7e93c6da644e2fc3bc5a39118f253562751fd295a8cc77/azure_common-1.1.18-py2.py3-none-any.whl\nCollecting backports.tempfile (from azureml-core==1.0.23.*->azureml-defaults->-r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 1))\n  Downloading https://files.pythonhosted.org/packages/b4/5c/077f910632476281428fe254807952eb47ca78e720d059a46178c541e669/backports.tempfile-1.0-py2.py3-none-any.whl\nCollecting cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.* (from azureml-core==1.0.23.*->azureml-defaults->-r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 1))\n  Downloading https://files.pythonhosted.org/packages/5b/12/b0409a94dad366d98a8eee2a77678c7a73aafd8c0e4b835abea634ea3896/cryptography-2.6.1-cp34-abi3-manylinux1_x86_64.whl (2.3MB)\nCollecting python-dateutil>=2.7.3 (from azureml-core==1.0.23.*->azureml-defaults->-r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 1))\n  Downloading https://files.pythonhosted.org/packages/41/17/c62faccbfbd163c7f57f3844689e3a78bae1f403648a6afb1d0866d87fbb/python_dateutil-2.8.0-py2.py3-none-any.whl (226kB)\nCollecting adal>=1.2.0 (from azureml-core==1.0.23.*->azureml-defaults->-r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 1))\n  Downloading https://files.pythonhosted.org/packages/00/72/53dce9e4f5d6c1aa57b8d408cb34dff1969ecbf10ab7e678f32c5e0e2397/adal-1.2.1-py2.py3-none-any.whl (52kB)\nCollecting azure-graphrbac>=0.40.0 (from azureml-core==1.0.23.*->azureml-defaults->-r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 1))\n  Downloading https://files.pythonhosted.org/packages/89/74/00a5ae6e8c823ff0a9c8550931fc42f5f1e5b614f7a45f602f52ec794ac9/azure_graphrbac-0.61.0-py2.py3-none-any.whl (141kB)\nCollecting azure-mgmt-storage>=1.5.0 (from azureml-core==1.0.23.*->azureml-defaults->-r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 1))\n  Downloading https://files.pythonhosted.org/packages/d9/87/ab44b9d9627ff91825ba5f5a39092ebfe97a90679008609db4c479036591/azure_mgmt_storage-3.1.1-py2.py3-none-any.whl (696kB)\nCollecting jsonpickle (from azureml-core==1.0.23.*->azureml-defaults->-r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 1))\n  Downloading https://files.pythonhosted.org/packages/dc/12/8c44eabb501e2bc0aec0dd152b328074d98a50968d3a02be28f6037f0c6a/jsonpickle-1.1-py2.py3-none-any.whl\nCollecting urllib3>=1.23 (from azureml-core==1.0.23.*->azureml-defaults->-r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 1))\n  Downloading https://files.pythonhosted.org/packages/62/00/ee1d7de624db8ba7090d1226aebefab96a2c71cd5cfa7629d6ad3f61b79e/urllib3-1.24.1-py2.py3-none-any.whl (118kB)\nCollecting SecretStorage (from azureml-core==1.0.23.*->azureml-defaults->-r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 1))\n  Downloading https://files.pythonhosted.org/packages/82/59/cb226752e20d83598d7fdcabd7819570b0329a61db07cfbdd21b2ef546e3/SecretStorage-3.1.1-py3-none-any.whl\nCollecting paramiko>=2.0.8 (from azureml-core==1.0.23.*->azureml-defaults->-r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 1))\n  Downloading https://files.pythonhosted.org/packages/cf/ae/94e70d49044ccc234bfdba20114fa947d7ba6eb68a2e452d89b920e62227/paramiko-2.4.2-py2.py3-none-any.whl (193kB)\nCollecting contextlib2 (from azureml-core==1.0.23.*->azureml-defaults->-r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 1))\n  Downloading https://files.pythonhosted.org/packages/a2/71/8273a7eeed0aff6a854237ab5453bc9aa67deb49df4832801c21f0ff3782/contextlib2-0.5.5-py2.py3-none-any.whl\nCollecting azure-mgmt-containerregistry>=2.0.0 (from azureml-core==1.0.23.*->azureml-defaults->-r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 1))\n  Downloading https://files.pythonhosted.org/packages/7a/4b/06040d992f93531e32c5f7cf7884f3edfec11f76f802dd9224c1116c3129/azure_mgmt_containerregistry-2.7.0-py2.py3-none-any.whl (509kB)\nCollecting ndg-httpsclient (from azureml-core==1.0.23.*->azureml-defaults->-r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 1))\n  Downloading https://files.pythonhosted.org/packages/fb/67/c2f508c00ed2a6911541494504b7cac16fe0b0473912568df65fd1801132/ndg_httpsclient-0.5.1-py3-none-any.whl\nCollecting msrest>=0.5.1 (from azureml-core==1.0.23.*->azureml-defaults->-r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 1))\n  Downloading https://files.pythonhosted.org/packages/d7/fa/bb4197e25ff01d089dc0584ad8e7d6c2615ae28b9e850afd165927c89576/msrest-0.6.6-py2.py3-none-any.whl (81kB)\nCollecting soupsieve>=1.2 (from beautifulsoup4->fastai->-r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 4))\n  Downloading https://files.pythonhosted.org/packages/c9/f8/e54b1d771ed4fab66b3fa1c178e137a3c73d84fb6f64329bddf0da5a371c/soupsieve-1.9-py2.py3-none-any.whl\nCollecting pyparsing>=2.0.2 (from packaging->fastai->-r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 4))\n  Downloading https://files.pythonhosted.org/packages/dd/d9/3ec19e966301a6e25769976999bd7bbe552016f0d32b577dc9d63d2e0c49/pyparsing-2.4.0-py2.py3-none-any.whl (62kB)\nRequirement already satisfied: certifi>=2017.4.17 in /azureml-envs/azureml_e7a13acf77779904bb28653701c4bd3a/lib/python3.6/site-packages (from requests->fastai->-r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 4)) (2019.3.9)\nCollecting idna<2.9,>=2.5 (from requests->fastai->-r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 4))\n  Downloading https://files.pythonhosted.org/packages/14/2c/cd551d81dbe15200be1cf41cd03869a46fe7226e7450af7a6545bfc474c9/idna-2.8-py2.py3-none-any.whl (58kB)\nCollecting chardet<3.1.0,>=3.0.2 (from requests->fastai->-r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 4))\n  Downloading https://files.pythonhosted.org/packages/bc/a9/01ffebfb562e4274b6487b4bb1ddec7ca55ec7510b22e4c51f14098443b8/chardet-3.0.4-py2.py3-none-any.whl (133kB)\nCollecting kiwisolver>=1.0.1 (from matplotlib->fastai->-r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 4))\n  Downloading https://files.pythonhosted.org/packages/69/a7/88719d132b18300b4369fbffa741841cfd36d1e637e1990f27929945b538/kiwisolver-1.0.1-cp36-cp36m-manylinux1_x86_64.whl (949kB)\nCollecting cycler>=0.10 (from matplotlib->fastai->-r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 4))\n  Downloading https://files.pythonhosted.org/packages/f7/d2/e07d3ebb2bd7af696440ce7e754c59dd546ffe1bbe732c8ab68b9c834e61/cycler-0.10.0-py2.py3-none-any.whl\nCollecting srsly<1.1.0,>=0.0.5 (from spacy>=2.0.18->fastai->-r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 4))\n  Downloading https://files.pythonhosted.org/packages/6b/97/47753e3393aa4b18de9f942fac26f18879d1ae950243a556888f389d1398/srsly-0.0.5-cp36-cp36m-manylinux1_x86_64.whl (180kB)\nCollecting thinc<7.1.0,>=7.0.2 (from spacy>=2.0.18->fastai->-r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 4))\n  Downloading https://files.pythonhosted.org/packages/a9/f1/3df317939a07b2fc81be1a92ac10bf836a1d87b4016346b25f8b63dee321/thinc-7.0.4-cp36-cp36m-manylinux1_x86_64.whl (2.1MB)\nCollecting murmurhash<1.1.0,>=0.28.0 (from spacy>=2.0.18->fastai->-r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 4))\n  Downloading https://files.pythonhosted.org/packages/a6/e6/63f160a4fdf0e875d16b28f972083606d8d54f56cd30cb8929f9a1ee700e/murmurhash-1.0.2-cp36-cp36m-manylinux1_x86_64.whl\nCollecting wasabi<1.1.0,>=0.2.0 (from spacy>=2.0.18->fastai->-r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 4))\n  Downloading https://files.pythonhosted.org/packages/76/6c/0376977df1ba9f0ec27835d80456d9284c79737cb5205649451db1181f01/wasabi-0.2.1-py3-none-any.whl\nCollecting blis<0.3.0,>=0.2.2 (from spacy>=2.0.18->fastai->-r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 4))\n  Downloading https://files.pythonhosted.org/packages/34/46/b1d0bb71d308e820ed30316c5f0a017cb5ef5f4324bcbc7da3cf9d3b075c/blis-0.2.4-cp36-cp36m-manylinux1_x86_64.whl (3.2MB)\nCollecting preshed<2.1.0,>=2.0.1 (from spacy>=2.0.18->fastai->-r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 4))\n  Downloading https://files.pythonhosted.org/packages/20/93/f222fb957764a283203525ef20e62008675fd0a14ffff8cc1b1490147c63/preshed-2.0.1-cp36-cp36m-manylinux1_x86_64.whl (83kB)\nCollecting cymem<2.1.0,>=2.0.2 (from spacy>=2.0.18->fastai->-r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 4))\n  Downloading https://files.pythonhosted.org/packages/3d/61/9b0520c28eb199a4b1ca667d96dd625bba003c14c75230195f9691975f85/cymem-2.0.2-cp36-cp36m-manylinux1_x86_64.whl\nCollecting plac<1.0.0,>=0.9.6 (from spacy>=2.0.18->fastai->-r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 4))\n  Downloading https://files.pythonhosted.org/packages/9e/9b/62c60d2f5bc135d2aa1d8c8a86aaf84edb719a59c7f11a4316259e61a298/plac-0.9.6-py2.py3-none-any.whl\nCollecting jsonschema<3.0.0,>=2.6.0 (from spacy>=2.0.18->fastai->-r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 4))\n  Downloading https://files.pythonhosted.org/packages/77/de/47e35a97b2b05c2fadbec67d44cfcdcd09b8086951b331d82de90d2912da/jsonschema-2.6.0-py2.py3-none-any.whl\nCollecting azureml-pipeline-core==1.0.23.* (from azureml-pipeline==1.0.23.*->azureml-sdk->-r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 5))\n  Downloading https://files.pythonhosted.org/packages/0c/f3/b1886ae4056c3dc1c4394801bdf2639af2979d449c66b8db1467404f4102/azureml_pipeline_core-1.0.23-py2.py3-none-any.whl (153kB)\nCollecting azureml-pipeline-steps==1.0.23.* (from azureml-pipeline==1.0.23.*->azureml-sdk->-r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 5))\n  Downloading https://files.pythonhosted.org/packages/56/40/84ca4c8c060621be9855e24150c165cc952fe33d2a09693336414d585a34/azureml_pipeline_steps-1.0.23-py3-none-any.whl\nCollecting azureml-train-core==1.0.23.* (from azureml-train==1.0.23.*->azureml-sdk->-r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 5))\n  Downloading https://files.pythonhosted.org/packages/60/1c/9f5765f2b90e3581898bc9e97132542fd74022a9579e446e05db5de6fece/azureml_train_core-1.0.23-py3-none-any.whl (40kB)\nCollecting websocket-client>=0.32.0 (from docker->azureml-core==1.0.23.*->azureml-defaults->-r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 1))\n  Downloading https://files.pythonhosted.org/packages/29/19/44753eab1fdb50770ac69605527e8859468f3c0fd7dc5a76dd9c4dbd7906/websocket_client-0.56.0-py2.py3-none-any.whl (200kB)\nCollecting docker-pycreds>=0.4.0 (from docker->azureml-core==1.0.23.*->azureml-defaults->-r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 1))\n  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl\nCollecting azure-mgmt-nspkg>=2.0.0 (from azure-mgmt-keyvault>=0.40.0->azureml-core==1.0.23.*->azureml-defaults->-r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 1))\n  Downloading https://files.pythonhosted.org/packages/b3/c2/af4b47845f27dc7d206ed4908b9e580f8bc94a4b2f3956a0d87c40719d90/azure_mgmt_nspkg-3.0.2-py3-none-any.whl\nCollecting backports.weakref (from backports.tempfile->azureml-core==1.0.23.*->azureml-defaults->-r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 1))\n  Downloading https://files.pythonhosted.org/packages/88/ec/f598b633c3d5ffe267aaada57d961c94fdfa183c5c3ebda2b6d151943db6/backports.weakref-1.0.post1-py2.py3-none-any.whl\nCollecting asn1crypto>=0.21.0 (from cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*->azureml-core==1.0.23.*->azureml-defaults->-r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 1))\n  Downloading https://files.pythonhosted.org/packages/ea/cd/35485615f45f30a510576f1a56d1e0a7ad7bd8ab5ed7cdc600ef7cd06222/asn1crypto-0.24.0-py2.py3-none-any.whl (101kB)\nCollecting cffi!=1.11.3,>=1.8 (from cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*->azureml-core==1.0.23.*->azureml-defaults->-r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 1))\n  Downloading https://files.pythonhosted.org/packages/20/f7/87b62a8895bf7c93e907b05b97bc4459c81a38a61151f03a6eae13d863aa/cffi-1.12.2-cp36-cp36m-manylinux1_x86_64.whl (428kB)\nCollecting jeepney (from SecretStorage->azureml-core==1.0.23.*->azureml-defaults->-r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 1))\n  Downloading https://files.pythonhosted.org/packages/2b/f7/ff23b9b59534f501d47c327576aadda59da5b83d76ff837e6075bc325b9f/jeepney-0.4-py3-none-any.whl (59kB)\nCollecting bcrypt>=3.1.3 (from paramiko>=2.0.8->azureml-core==1.0.23.*->azureml-defaults->-r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 1))\n  Downloading https://files.pythonhosted.org/packages/d0/79/79a4d167a31cc206117d9b396926615fa9c1fdbd52017bcced80937ac501/bcrypt-3.1.6-cp34-abi3-manylinux1_x86_64.whl (55kB)\nCollecting pynacl>=1.0.1 (from paramiko>=2.0.8->azureml-core==1.0.23.*->azureml-defaults->-r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 1))\n  Downloading https://files.pythonhosted.org/packages/27/15/2cd0a203f318c2240b42cd9dd13c931ddd61067809fee3479f44f086103e/PyNaCl-1.3.0-cp34-abi3-manylinux1_x86_64.whl (759kB)\nCollecting pyasn1>=0.1.7 (from paramiko>=2.0.8->azureml-core==1.0.23.*->azureml-defaults->-r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 1))\n  Downloading https://files.pythonhosted.org/packages/7b/7c/c9386b82a25115cccf1903441bba3cbadcfae7b678a20167347fa8ded34c/pyasn1-0.4.5-py2.py3-none-any.whl (73kB)\nCollecting requests-oauthlib>=0.5.0 (from msrest>=0.5.1->azureml-core==1.0.23.*->azureml-defaults->-r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 1))\n  Downloading https://files.pythonhosted.org/packages/c2/e2/9fd03d55ffb70fe51f587f20bcf407a6927eb121de86928b34d162f0b1ac/requests_oauthlib-1.2.0-py2.py3-none-any.whl\nCollecting isodate>=0.6.0 (from msrest>=0.5.1->azureml-core==1.0.23.*->azureml-defaults->-r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 1))\n  Downloading https://files.pythonhosted.org/packages/9b/9f/b36f7774ff5ea8e428fdcfc4bb332c39ee5b9362ddd3d40d9516a55221b2/isodate-0.6.0-py2.py3-none-any.whl (45kB)\nRequirement already satisfied: setuptools in /azureml-envs/azureml_e7a13acf77779904bb28653701c4bd3a/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib->fastai->-r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 4)) (40.8.0)\nCollecting tqdm<5.0.0,>=4.10.0 (from thinc<7.1.0,>=7.0.2->spacy>=2.0.18->fastai->-r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 4))\n  Downloading https://files.pythonhosted.org/packages/6c/4b/c38b5144cf167c4f52288517436ccafefe9dc01b8d1c190e18a6b154cd4a/tqdm-4.31.1-py2.py3-none-any.whl (48kB)\nCollecting azureml-telemetry==1.0.23.* (from azureml-train-core==1.0.23.*->azureml-train==1.0.23.*->azureml-sdk->-r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 5))\n  Downloading https://files.pythonhosted.org/packages/3b/8f/5618c3535a6ce6aafd7fffd640e03ad7524ab2ca4b3a7258b00eef9acead/azureml_telemetry-1.0.23-py3-none-any.whl\nCollecting azureml-train-restclients-hyperdrive==1.0.23.* (from azureml-train-core==1.0.23.*->azureml-train==1.0.23.*->azureml-sdk->-r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 5))\n  Downloading https://files.pythonhosted.org/packages/be/41/1d498b21df9d17972ce3665f3b98993b8caeb3b9feef49d41be5c70371df/azureml_train_restclients_hyperdrive-1.0.23-py3-none-any.whl\nCollecting azure-nspkg>=3.0.0 (from azure-mgmt-nspkg>=2.0.0->azure-mgmt-keyvault>=0.40.0->azureml-core==1.0.23.*->azureml-defaults->-r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 1))\n  Downloading https://files.pythonhosted.org/packages/c4/0c/c562be95a9a2ed52454f598571cf300b1114d0db2aa27f5b8ed3bb9cd0c0/azure_nspkg-3.0.2-py3-none-any.whl\nCollecting pycparser (from cffi!=1.11.3,>=1.8->cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*->azureml-core==1.0.23.*->azureml-defaults->-r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 1))\n  Downloading https://files.pythonhosted.org/packages/68/9e/49196946aee219aead1290e00d1e7fdeab8567783e83e1b9ab5585e6206a/pycparser-2.19.tar.gz (158kB)\nCollecting oauthlib>=3.0.0 (from requests-oauthlib>=0.5.0->msrest>=0.5.1->azureml-core==1.0.23.*->azureml-defaults->-r /azureml-setup/condaenv.w9vfbr24.requirements.txt (line 1))\n  Downloading https://files.pythonhosted.org/packages/16/95/699466b05b72b94a41f662dc9edf87fda4289e3602ecd42d27fcaddf7b56/oauthlib-3.0.1-py2.py3-none-any.whl (142kB)\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "Building wheels for collected packages: pyyaml, bottleneck, nvidia-ml-py3, pathspec, pycparser\n  Building wheel for pyyaml (setup.py): started\n  Building wheel for pyyaml (setup.py): finished with status 'done'\n  Stored in directory: /root/.cache/pip/wheels/ad/56/bc/1522f864feb2a358ea6f1a92b4798d69ac783a28e80567a18b\n  Building wheel for bottleneck (setup.py): started\n  Building wheel for bottleneck (setup.py): finished with status 'done'\n  Stored in directory: /root/.cache/pip/wheels/f2/bf/ec/e0f39aa27001525ad455139ee57ec7d0776fe074dfd78c97e4\n  Building wheel for nvidia-ml-py3 (setup.py): started\n  Building wheel for nvidia-ml-py3 (setup.py): finished with status 'done'\n  Stored in directory: /root/.cache/pip/wheels/e4/1d/06/640c93f5270d67d0247f30be91f232700d19023f9e66d735c7\n  Building wheel for pathspec (setup.py): started\n  Building wheel for pathspec (setup.py): finished with status 'done'\n  Stored in directory: /root/.cache/pip/wheels/45/cb/7e/ce6e6062c69446e39e328170524ca8213498bc66a74c6a210b\n  Building wheel for pycparser (setup.py): started\n  Building wheel for pycparser (setup.py): finished with status 'done'\n  Stored in directory: /root/.cache/pip/wheels/f2/9a/90/de94f8556265ddc9d9c8b271b0f63e57b26fb1d67a45564511\nSuccessfully built pyyaml bottleneck nvidia-ml-py3 pathspec pycparser\nInstalling collected packages: six, asn1crypto, pycparser, cffi, cryptography, PyJWT, urllib3, idna, chardet, requests, python-dateutil, adal, oauthlib, requests-oauthlib, isodate, msrest, msrestazure, azure-common, azure-mgmt-authorization, azure-mgmt-resource, websocket-client, docker-pycreds, docker, jmespath, ruamel.yaml, pathspec, azure-nspkg, azure-mgmt-nspkg, azure-mgmt-keyvault, pyopenssl, pytz, backports.weakref, backports.tempfile, azure-graphrbac, azure-mgmt-storage, jsonpickle, jeepney, SecretStorage, bcrypt, pynacl, pyasn1, paramiko, contextlib2, azure-mgmt-containerregistry, ndg-httpsclient, azureml-core, applicationinsights, azureml-defaults, torch, pillow, numpy, torchvision, soupsieve, beautifulsoup4, pyyaml, bottleneck, numexpr, nvidia-ml-py3, pandas, fastprogress, pyparsing, packaging, typing, scipy, kiwisolver, cycler, matplotlib, dataclasses, srsly, tqdm, cymem, preshed, murmurhash, wasabi, plac, blis, thinc, jsonschema, spacy, fastai, azureml-pipeline-core, azureml-telemetry, azureml-train-restclients-hyperdrive, azureml-train-core, azureml-pipeline-steps, azureml-pipeline, azureml-train, azureml-sdk\nSuccessfully installed PyJWT-1.7.1 SecretStorage-3.1.1 adal-1.2.1 applicationinsights-0.11.8 asn1crypto-0.24.0 azure-common-1.1.18 azure-graphrbac-0.61.0 azure-mgmt-authorization-0.51.1 azure-mgmt-containerregistry-2.7.0 azure-mgmt-keyvault-1.1.0 azure-mgmt-nspkg-3.0.2 azure-mgmt-resource-2.1.0 azure-mgmt-storage-3.1.1 azure-nspkg-3.0.2 azureml-core-1.0.23 azureml-defaults-1.0.23 azureml-pipeline-1.0.23 azureml-pipeline-core-1.0.23 azureml-pipeline-steps-1.0.23 azureml-sdk-1.0.23 azureml-telemetry-1.0.23 azureml-train-1.0.23 azureml-train-core-1.0.23 azureml-train-restclients-hyperdrive-1.0.23 backports.tempfile-1.0 backports.weakref-1.0.post1 bcrypt-3.1.6 beautifulsoup4-4.7.1 blis-0.2.4 bottleneck-1.2.1 cffi-1.12.2 chardet-3.0.4 contextlib2-0.5.5 cryptography-2.6.1 cycler-0.10.0 cymem-2.0.2 dataclasses-0.6 docker-3.7.2 docker-pycreds-0.4.0 fastai-1.0.51 fastprogress-0.1.21 idna-2.8 isodate-0.6.0 jeepney-0.4 jmespath-0.9.4 jsonpickle-1.1 jsonschema-2.6.0 kiwisolver-1.0.1 matplotlib-3.0.3 msrest-0.6.6 msrestazure-0.6.0 murmurhash-1.0.2 ndg-httpsclient-0.5.1 numexpr-2.6.9 numpy-1.16.2 nvidia-ml-py3-7.352.0 oauthlib-3.0.1 packaging-19.0 pandas-0.24.2 paramiko-2.4.2 pathspec-0.5.9 pillow-6.0.0 plac-0.9.6 preshed-2.0.1 pyasn1-0.4.5 pycparser-2.19 pynacl-1.3.0 pyopenssl-19.0.0 pyparsing-2.4.0 python-dateutil-2.8.0 pytz-2018.9 pyyaml-5.1 requests-2.21.0 requests-oauthlib-1.2.0 ruamel.yaml-0.15.89 scipy-1.2.1 six-1.12.0 soupsieve-1.9 spacy-2.1.3 srsly-0.0.5 thinc-7.0.4 torch-1.0.0 torchvision-0.2.1 tqdm-4.31.1 typing-3.6.6 urllib3-1.24.1 wasabi-0.2.1 websocket-client-0.56.0\n\u001b[91m\n\u001b[0m#\n# To activate this environment, use:\n# > source activate /azureml-envs/azureml_e7a13acf77779904bb28653701c4bd3a\n#\n# To deactivate an active environment, use:\n# > source deactivate\n#\n\nRemoving intermediate container 06ed5edfb4a1\n ---> 5dd9797aea4c\nStep 9/15 : ENV PATH /azureml-envs/azureml_e7a13acf77779904bb28653701c4bd3a/bin:$PATH\n ---> Running in 3de2f2f90715\nRemoving intermediate container 3de2f2f90715\n ---> 76dc0ea8062c\nStep 10/15 : ENV AZUREML_CONDA_ENVIRONMENT_PATH /azureml-envs/azureml_e7a13acf77779904bb28653701c4bd3a\n ---> Running in 547cfd80f35b\nRemoving intermediate container 547cfd80f35b\n ---> 40ecd0f688b8\nStep 11/15 : ENV LD_LIBRARY_PATH /azureml-envs/azureml_e7a13acf77779904bb28653701c4bd3a/lib:$LD_LIBRARY_PATH\n ---> Running in 1cc6d2965571\nRemoving intermediate container 1cc6d2965571\n ---> 977af0315518\nStep 12/15 : COPY azureml-setup/spark_cache.py azureml-setup/log4j.properties /azureml-setup/\n ---> d03a961d06bf\nStep 13/15 : RUN if [ $SPARK_HOME ]; then /bin/bash -c '$SPARK_HOME/bin/spark-submit \"--repositories\" \"https://mmlspark.azureedge.net/maven\" \"--packages\" \"com.microsoft.ml.spark:mmlspark_2.11:0.12\" /azureml-setup/spark_cache.py'; fi\n ---> Running in 428b8bf974d3\nRemoving intermediate container 428b8bf974d3\n ---> cfaf09f5fdcf\nStep 14/15 : ENV AZUREML_ENVIRONMENT_IMAGE True\n ---> Running in b824d2a742fa\nRemoving intermediate container b824d2a742fa\n ---> d46ffee54add\nStep 15/15 : CMD [\"bash\"]\n ---> Running in 9b84f2eb1a2d\nRemoving intermediate container 9b84f2eb1a2d\n ---> 48c82fc307cf\nSuccessfully built 48c82fc307cf\nSuccessfully tagged aamlamlwacrhtyjtxxl.azurecr.io/azureml/azureml_24d7727f17861faa4a6d349bf1aa456a:latest\n2019/04/09 14:59:02 Successfully executed container: acb_step_0\n2019/04/09 14:59:02 Executing step ID: acb_step_1. Working directory: '', Network: 'acb_default_network'\n2019/04/09 14:59:02 Pushing image: aamlamlwacrhtyjtxxl.azurecr.io/azureml/azureml_24d7727f17861faa4a6d349bf1aa456a:latest, attempt 1\nThe push refers to repository [aamlamlwacrhtyjtxxl.azurecr.io/azureml/azureml_24d7727f17861faa4a6d349bf1aa456a]\nfa6e65f8b69f: Preparing\n010c7f1cdb78: Preparing\n699d47684a89: Preparing\n0aef9d245172: Preparing\n1b7b6b7587db: Preparing\nc5088e4dcdf9: Preparing\n1af194b284e7: Preparing\na47a9623d406: Preparing\n51713b8e3669: Preparing\nbf847be1c797: Preparing\n553141bf0a37: Preparing\n5fb2a9818ab4: Preparing\n68dda0c9a8cd: Preparing\nf67191ae09b8: Preparing\nb2fd8b4c3da7: Preparing\n0de2edf7bff4: Preparing\nc5088e4dcdf9: Waiting\n1af194b284e7: Waiting\na47a9623d406: Waiting\n51713b8e3669: Waiting\nbf847be1c797: Waiting\n553141bf0a37: Waiting\n5fb2a9818ab4: Waiting\n68dda0c9a8cd: Waiting\nf67191ae09b8: Waiting\nb2fd8b4c3da7: Waiting\n0de2edf7bff4: Waiting\nfa6e65f8b69f: Pushed\n0aef9d245172: Pushed\n699d47684a89: Pushed\n1b7b6b7587db: Pushed\na47a9623d406: Pushed\n51713b8e3669: Pushed\n1af194b284e7: Pushed\n5fb2a9818ab4: Pushed\n68dda0c9a8cd: Pushed\nf67191ae09b8: Pushed\nb2fd8b4c3da7: Pushed\n553141bf0a37: Pushed\n0de2edf7bff4: Pushed\nbf847be1c797: Pushed\nc5088e4dcdf9: Pushed\n010c7f1cdb78: Pushed\nlatest: digest: sha256:8d862f615eefaae37d95cd336fe4e63be434bf8243fd5c8574fc077ae77be9f2 size: 3680\n2019/04/09 15:03:39 Successfully pushed image: aamlamlwacrhtyjtxxl.azurecr.io/azureml/azureml_24d7727f17861faa4a6d349bf1aa456a:latest\n2019/04/09 15:03:39 Step ID: acb_step_0 marked as successful (elapsed time in seconds: 281.657839)\n2019/04/09 15:03:39 Populating digests for step ID: acb_step_0...\n2019/04/09 15:03:41 Successfully populated digests for step ID: acb_step_0\n2019/04/09 15:03:41 Step ID: acb_step_1 marked as successful (elapsed time in seconds: 277.116352)\n2019/04/09 15:03:41 The following dependencies were found:\n2019/04/09 15:03:41 \n- image:\n    registry: aamlamlwacrhtyjtxxl.azurecr.io\n    repository: azureml/azureml_24d7727f17861faa4a6d349bf1aa456a\n    tag: latest\n    digest: sha256:8d862f615eefaae37d95cd336fe4e63be434bf8243fd5c8574fc077ae77be9f2\n  runtime-dependency:\n    registry: mcr.microsoft.com\n    repository: azureml/base-gpu\n    tag: 0.2.1\n    digest: sha256:eb26cf5e4a6852a3b9029299ee17424b31f458b293066c11824135530617a073\n  git: {}\n\n\nRun ID: ca9 was successful after 9m25s\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "\nStreaming azureml-logs/60_control_log.txt\n=========================================\n\nStreaming log file azureml-logs/60_control_log.txt\nStreaming log file azureml-logs/80_driver_log.txt\n\nStreaming azureml-logs/80_driver_log.txt\n========================================\n\nPyTorch version 1.0.0\nfastai version: 1.0.51\nCUDA supported: True\nCUDNN enabled: True\nDownloading http://files.fast.ai/data/examples/dogscats\n/azureml-envs/azureml_e7a13acf77779904bb28653701c4bd3a/lib/python3.6/site-packages/fastai/vision/learner.py:105: UserWarning: `create_cnn` is deprecated and is now named `cnn_learner`.\n  warn(\"`create_cnn` is deprecated and is now named `cnn_learner`.\")\nDownloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.torch/models/resnet50-19c8e357.pth\n\n  0%|          | 0/102502400 [00:00<?, ?it/s]\n  3%|▎         | 3555328/102502400 [00:00<00:02, 35544331.00it/s]\n  6%|▌         | 6356992/102502400 [00:00<00:02, 32837547.98it/s]\n  9%|▊         | 8847360/102502400 [00:00<00:03, 29776279.41it/s]\n 11%|█▏        | 11599872/102502400 [00:00<00:03, 28989967.53it/s]\n 14%|█▍        | 14417920/102502400 [00:00<00:03, 28731074.86it/s]\n 17%|█▋        | 17235968/102502400 [00:00<00:02, 28432887.90it/s]\n 19%|█▉        | 19791872/102502400 [00:00<00:03, 27487664.17it/s]\n 22%|██▏       | 22347776/102502400 [00:00<00:02, 26797322.86it/s]\n 24%|██▍       | 24903680/102502400 [00:00<00:02, 25956019.52it/s]\n 27%|██▋       | 27721728/102502400 [00:01<00:02, 26541914.36it/s]\n 30%|██▉       | 30367744/102502400 [00:01<00:02, 26514111.75it/s]\n 32%|███▏      | 33161216/102502400 [00:01<00:02, 26891099.20it/s]\n 35%|███▌      | 35979264/102502400 [00:01<00:02, 27146424.79it/s]\n 38%|███▊      | 38756352/102502400 [00:01<00:02, 27328280.27it/s]\n 40%|████      | 41476096/102502400 [00:01<00:02, 27225598.47it/s]\n 43%|████▎     | 44236800/102502400 [00:01<00:02, 27322516.13it/s]\n 46%|████▌     | 46964736/102502400 [00:01<00:02, 26029143.48it/s]\n 48%|████▊     | 49676288/102502400 [00:01<00:02, 26341858.06it/s]\n 51%|█████     | 52363264/102502400 [00:01<00:01, 26349395.68it/s]\n 54%|█████▍    | 55246848/102502400 [00:02<00:01, 26942770.17it/s]\n 57%|█████▋    | 57950208/102502400 [00:02<00:01, 26859240.67it/s]\n 59%|█████▉    | 60735488/102502400 [00:02<00:01, 27147634.98it/s]\n 62%|██████▏   | 63455232/102502400 [00:02<00:01, 26736920.01it/s]\n 65%|██████▍   | 66256896/102502400 [00:02<00:01, 26996632.81it/s]\n 67%|██████▋   | 69009408/102502400 [00:02<00:01, 27145650.11it/s]\n 70%|██████▉   | 71729152/102502400 [00:02<00:01, 26993003.87it/s]\n 73%|███████▎  | 74432512/102502400 [00:02<00:01, 26976342.67it/s]\n 75%|███████▌  | 77135872/102502400 [00:02<00:00, 26689226.45it/s]\n 78%|███████▊  | 79888384/102502400 [00:02<00:00, 26905038.52it/s]\n 81%|████████  | 82788352/102502400 [00:03<00:00, 27178972.53it/s]\n 83%|████████▎ | 85508096/102502400 [00:03<00:00, 25947404.28it/s]\n 86%|████████▌ | 88121344/102502400 [00:03<00:00, 24712478.22it/s]\n 89%|████████▊ | 90767360/102502400 [00:03<00:00, 25165066.32it/s]\n 91%|█████████ | 93388800/102502400 [00:03<00:00, 25465087.65it/s]\n 94%|█████████▍| 96141312/102502400 [00:03<00:00, 25967647.78it/s]\n 96%|█████████▋| 98820096/102502400 [00:03<00:00, 26205676.15it/s]\n 99%|█████████▉| 101646336/102502400 [00:03<00:00, 26689593.57it/s]\n100%|██████████| 102502400/102502400 [00:03<00:00, 26806846.87it/s]\nepoch     train_loss  valid_loss  accuracy  time    \n0         0.046447    0.028365    0.987000  06:39     \nepoch     train_loss  valid_loss  accuracy  time    \n0         0.027643    0.018494    0.993000  08:46     \n\n\nThe experiment failed. Finalizing run...\nLogging experiment finalizing status in history service\nCleaning up all outstanding Run operations, waiting 300.0 seconds\n1 items cleaning up...\nCleanup took 0.2507138252258301 seconds\nTraceback (most recent call last):\n  File \"azureml-setup/context_manager_injector.py\", line 161, in <module>\n    execute_with_context(cm_objects, options.invocation)\n  File \"azureml-setup/context_manager_injector.py\", line 90, in execute_with_context\n    runpy.run_path(sys.argv[0], globals(), run_name=\"__main__\")\n  File \"/azureml-envs/azureml_e7a13acf77779904bb28653701c4bd3a/lib/python3.6/runpy.py\", line 263, in run_path\n    pkg_name=pkg_name, script_name=fname)\n  File \"/azureml-envs/azureml_e7a13acf77779904bb28653701c4bd3a/lib/python3.6/runpy.py\", line 96, in _run_module_code\n    mod_name, mod_spec, pkg_name, script_name)\n  File \"/azureml-envs/azureml_e7a13acf77779904bb28653701c4bd3a/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"train.py\", line 21, in <module>\n    saved_model_path = learn.save(name='cats-vs-dogs', return_path = True)\nTypeError: save() got an unexpected keyword argument 'name'\n\nExecution Summary\n=================\nRunId: azureml-cats-vs-dogs_1554821600_f6d06459\nError:\n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"save() got an unexpected keyword argument 'name'\",\n        \"details\": [],\n        \"debugInfo\": {\n            \"type\": \"TypeError\",\n            \"message\": \"save() got an unexpected keyword argument 'name'\",\n            \"stackTrace\": \"  File \\\"azureml-setup/context_manager_injector.py\\\", line 90, in execute_with_context\\n    runpy.run_path(sys.argv[0], globals(), run_name=\\\"__main__\\\")\\n  File \\\"/azureml-envs/azureml_e7a13acf77779904bb28653701c4bd3a/lib/python3.6/runpy.py\\\", line 263, in run_path\\n    pkg_name=pkg_name, script_name=fname)\\n  File \\\"/azureml-envs/azureml_e7a13acf77779904bb28653701c4bd3a/lib/python3.6/runpy.py\\\", line 96, in _run_module_code\\n    mod_name, mod_spec, pkg_name, script_name)\\n  File \\\"/azureml-envs/azureml_e7a13acf77779904bb28653701c4bd3a/lib/python3.6/runpy.py\\\", line 85, in _run_code\\n    exec(code, run_globals)\\n  File \\\"train.py\\\", line 21, in <module>\\n    saved_model_path = learn.save(name='cats-vs-dogs', return_path = True)\\n\"\n        }\n    }\n}\n\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 15,
          "data": {
            "text/plain": "{'runId': 'azureml-cats-vs-dogs_1554821600_f6d06459',\n 'target': 'amlcompute',\n 'status': 'Failed',\n 'startTimeUtc': '2019-04-09T15:07:55.494566Z',\n 'endTimeUtc': '2019-04-09T15:26:29.228121Z',\n 'error': {'error': {'code': 'UserError',\n   'message': \"save() got an unexpected keyword argument 'name'\",\n   'details': [],\n   'debugInfo': {'type': 'TypeError',\n    'message': \"save() got an unexpected keyword argument 'name'\",\n    'stackTrace': '  File \"azureml-setup/context_manager_injector.py\", line 90, in execute_with_context\\n    runpy.run_path(sys.argv[0], globals(), run_name=\"__main__\")\\n  File \"/azureml-envs/azureml_e7a13acf77779904bb28653701c4bd3a/lib/python3.6/runpy.py\", line 263, in run_path\\n    pkg_name=pkg_name, script_name=fname)\\n  File \"/azureml-envs/azureml_e7a13acf77779904bb28653701c4bd3a/lib/python3.6/runpy.py\", line 96, in _run_module_code\\n    mod_name, mod_spec, pkg_name, script_name)\\n  File \"/azureml-envs/azureml_e7a13acf77779904bb28653701c4bd3a/lib/python3.6/runpy.py\", line 85, in _run_code\\n    exec(code, run_globals)\\n  File \"train.py\", line 21, in <module>\\n    saved_model_path = learn.save(name=\\'cats-vs-dogs\\', return_path = True)\\n'}}},\n 'warnings': [{'source': 'SecondaryError',\n   'message': '{\\n  \"error\": {\\n    \"code\": \"UserError\",\\n    \"message\": \"AmlCompute job failed.\\\\nJobFailed: Job failed with non-zero exit Code\",\\n    \"target\": null,\\n    \"details\": [],\\n    \"innerError\": null,\\n    \"debugInfo\": null\\n  },\\n  \"correlation\": {\\n    \"operation\": null,\\n    \"request\": \"jKMffsKB7L4=\"\\n  },\\n  \"location\": \"eastus\",\\n  \"time\": \"2019-04-09T15:26:06.1120704+00:00\"\\n}'},\n  {'source': 'SecondaryError',\n   'message': '{\\n  \"error\": {\\n    \"code\": \"UserError\",\\n    \"message\": \"AmlCompute job failed.\\\\nJobFailed: Job failed with non-zero exit Code\",\\n    \"target\": null,\\n    \"details\": [],\\n    \"innerError\": null,\\n    \"debugInfo\": null\\n  },\\n  \"correlation\": {\\n    \"operation\": null,\\n    \"request\": \"aupi18jzxnc=\"\\n  },\\n  \"location\": \"eastus\",\\n  \"time\": \"2019-04-09T15:26:27.1258801+00:00\"\\n}'},\n  {'source': 'SecondaryError',\n   'message': '{\\n  \"error\": {\\n    \"code\": \"UserError\",\\n    \"message\": \"Compute target amlcompute is in state deleting and thus not ready for runs.\",\\n    \"target\": null,\\n    \"details\": [],\\n    \"innerError\": null,\\n    \"debugInfo\": null\\n  },\\n  \"correlation\": {\\n    \"operation\": null,\\n    \"request\": \"3/4E02ilapw=\"\\n  },\\n  \"location\": \"eastus\",\\n  \"time\": \"2019-04-09T15:26:29.0039949+00:00\"\\n}'}],\n 'properties': {'azureml.runsource': 'experiment',\n  'AzureML.DerivedImageName': 'azureml/azureml_24d7727f17861faa4a6d349bf1aa456a',\n  'ContentSnapshotId': '6d827214-48af-4f87-989c-60acc89c9c84'},\n 'runDefinition': {'script': 'train.py',\n  'arguments': [],\n  'sourceDirectoryDataStore': None,\n  'framework': 'Python',\n  'communicator': 'None',\n  'target': 'amlcompute',\n  'dataReferences': {},\n  'jobName': None,\n  'autoPrepareEnvironment': True,\n  'maxRunDurationSeconds': None,\n  'nodeCount': 1,\n  'environment': {'name': 'Experiment azureml-cats-vs-dogs Environment',\n   'version': 'auto_c799318c1aa746079bc0acfd390701ad',\n   'python': {'interpreterPath': 'python',\n    'userManagedDependencies': False,\n    'condaDependencies': {'name': 'project_environment',\n     'dependencies': ['python=3.6.2',\n      {'pip': ['azureml-defaults',\n        'torch==1.0.0',\n        'torchvision==0.2.1',\n        'fastai',\n        'azureml-sdk']}]},\n    'baseCondaEnvironment': None},\n   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE',\n    'NCCL_SOCKET_IFNAME': '^docker0'},\n   'docker': {'baseImage': 'mcr.microsoft.com/azureml/base-gpu:0.2.1',\n    'enabled': True,\n    'sharedVolumes': True,\n    'preparation': None,\n    'gpuSupport': True,\n    'shmSize': '1g',\n    'arguments': [],\n    'baseImageRegistry': {'address': None,\n     'username': None,\n     'password': None}},\n   'spark': {'repositories': ['https://mmlspark.azureedge.net/maven'],\n    'packages': [{'group': 'com.microsoft.ml.spark',\n      'artifact': 'mmlspark_2.11',\n      'version': '0.12'}],\n    'precachePackages': True}},\n  'history': {'outputCollection': True, 'snapshotProject': True},\n  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n    'spark.yarn.maxAppAttempts': '1'}},\n  'amlCompute': {'name': None,\n   'vmSize': 'Standard_NC6',\n   'vmPriority': None,\n   'retainCluster': False,\n   'clusterMaxNodeCount': 1},\n  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n  'mpi': {'processCountPerNode': 1},\n  'hdi': {'yarnDeployMode': 'Cluster'},\n  'containerInstance': {'region': None, 'cpuCores': 2, 'memoryGb': 3.5},\n  'exposedPorts': None},\n 'logFiles': {'azureml-logs/20_image_build_log.txt': 'https://aamlamlwstoragedlooyobn.blob.core.windows.net/azureml/ExperimentRun/dcid.azureml-cats-vs-dogs_1554821600_f6d06459/azureml-logs/20_image_build_log.txt?sv=2018-03-28&sr=b&sig=KFLUVWqNwSc5FM1ETIhro21X0ZUNnVjwmfNc3bd8seo%3D&st=2019-04-09T15%3A16%3A30Z&se=2019-04-09T23%3A26%3A30Z&sp=r',\n  'azureml-logs/60_control_log.txt': 'https://aamlamlwstoragedlooyobn.blob.core.windows.net/azureml/ExperimentRun/dcid.azureml-cats-vs-dogs_1554821600_f6d06459/azureml-logs/60_control_log.txt?sv=2018-03-28&sr=b&sig=94lK%2FtAn0LtArsBLv8I%2FdR%2Byxf5vzs9rBS7YPD96rFg%3D&st=2019-04-09T15%3A16%3A30Z&se=2019-04-09T23%3A26%3A30Z&sp=r',\n  'azureml-logs/80_driver_log.txt': 'https://aamlamlwstoragedlooyobn.blob.core.windows.net/azureml/ExperimentRun/dcid.azureml-cats-vs-dogs_1554821600_f6d06459/azureml-logs/80_driver_log.txt?sv=2018-03-28&sr=b&sig=CONFqqGsQC%2FHgwjrtHKbGdfyodCZrrDsYZXmgeCT0eg%3D&st=2019-04-09T15%3A16%3A30Z&se=2019-04-09T23%3A26%3A30Z&sp=r',\n  'azureml-logs/azureml.log': 'https://aamlamlwstoragedlooyobn.blob.core.windows.net/azureml/ExperimentRun/dcid.azureml-cats-vs-dogs_1554821600_f6d06459/azureml-logs/azureml.log?sv=2018-03-28&sr=b&sig=Cnvhz6qgfTIHUcx4bUIdWkDgRyapTSOtjAqA1%2BA1igI%3D&st=2019-04-09T15%3A16%3A30Z&se=2019-04-09T23%3A26%3A30Z&sp=r',\n  'azureml-logs/56_batchai_stderr.txt': 'https://aamlamlwstoragedlooyobn.blob.core.windows.net/azureml/ExperimentRun/dcid.azureml-cats-vs-dogs_1554821600_f6d06459/azureml-logs/56_batchai_stderr.txt?sv=2018-03-28&sr=b&sig=ErfM0JQPjUsu6ofvNNJPcivRSYPW3bapXQhrvadgcTw%3D&st=2019-04-09T15%3A16%3A30Z&se=2019-04-09T23%3A26%3A30Z&sp=r',\n  'azureml-logs/55_batchai_execution.txt': 'https://aamlamlwstoragedlooyobn.blob.core.windows.net/azureml/ExperimentRun/dcid.azureml-cats-vs-dogs_1554821600_f6d06459/azureml-logs/55_batchai_execution.txt?sv=2018-03-28&sr=b&sig=NS7Z%2F6ub%2F9jphBw6Xkave2e0P9n4PolDLoQzwRuOXz4%3D&st=2019-04-09T15%3A16%3A30Z&se=2019-04-09T23%3A26%3A30Z&sp=r'}}"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Visualize experiment"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "There are two ways to visualize the experiment results. Either by using:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.widgets import RunDetails\nRunDetails(run).show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "All the metrics you track can be seen within the portal in Azure too\n\n<img src='https://cdn-images-1.medium.com/max/1200/1*vuo42vDq9ml5Z2iyS4qYeg.png' width='800' />\n\nAs you can see, AML has added a couple of metrics to the dashboard automatically, like Base Model Name and Training Accuracy. This happens automatically, but you can customize the dashboard to show the metrics you are interested in. If you want to see all the metrics of a particular run, you just click on it:\n\n<img src='https://cdn-images-1.medium.com/max/1200/1*g5iHNpVQg15jZ_uqKbR4QA.png' width='800' />\n\nAs you see, now we have more variables being tracked. If you take a closer look, I’m also tracking two charts: Learning Rate and Loss. They show how the learning rate and the Loss are evolving as the training takes more samples on each epoch (I’m training with Stochastic Gradient Descent — SGD). It is useful to know when to stop training."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "markdown",
      "source": "### Test the model for inference"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import torch\nfrom fastai import *\nfrom fastai.vision import *",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "learn_inference = load_learner('/home/santiagxf/.fastai/data/dogscats')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Let's download an image from internet and submit it to the model we created"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "!wget -O test.jpg https://thenypost.files.wordpress.com/2018/05/180516-woman-mauled-by-angry-wiener-dogs-feature.jpg\n    \nimg = open_image(os.path.join(os.getcwd(),\"test.jpg\"))\nresult = learn_inference.predict(img)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "pytorch",
      "display_name": "Python (pytorch-py362)",
      "language": "python"
    },
    "language_info": {
      "version": "3.6.2",
      "nbconvert_exporter": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "mimetype": "text/x-python",
      "name": "python",
      "file_extension": ".py",
      "pygments_lexer": "ipython3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}